{"cells":[{"cell_type":"markdown","metadata":{"id":"HcfmVOR5ZpbT"},"source":["# scikit-learn (sklearn) で線形回帰（重回帰）を動かす\n","**scikit-learn (sklearn)はPythonの機械学習ライブラリ**です．公式：https://scikit-learn.org/stable/\n","\n","sklearnを用いると，驚くべきことに，**ライブラリのインポート・データの読み込みを除けば10行未満で学習・予測**まで行うことができます．\n","Pythonなので遅いのではないか（自分でCで書いた方が速いのではないか）と思うかもしれませんが，sklearnではNumPyやSciPyを上手く用いて書かれたコードや，Cで書かれた大変質の良いコードが動いているため，sklearnはかなり高速に動作します．\n","ほとんどの場合，雑に書いたCのプログラムよりは高速に動作します．\n","またPythonに慣れていなくとも，「慣れていないPythonでscikit-learnを使えるようになる時間」と「慣れているCで実装する時間」だと，おそらく圧倒的に前者の方が短いでしょう．\n","\n","勿論，勉強のためにsklearnを使わずに実装しても構いませんが，本演習ではデータ分析全体の流れを体験してもらいたいため，サンプルコードではsklearnを用います．"]},{"cell_type":"markdown","metadata":{"id":"UPiKpvGtZpbU"},"source":["## 今回学ぶこと\n","- pandasによるcsvの読み込みと簡単な操作（列・行へのアクセス，`numpy.ndarray`への変換）\n","- sklearnの基本的な使い方\n","- 提出までの流れ：\n","  1. 特徴ベクトルの作成\n","  2. モデル・アルゴリズムの選定，学習\n","  4. 予測\n","  5. 提出"]},{"cell_type":"markdown","metadata":{"id":"-nI89-u1ZpbV"},"source":["## 予測モデル構築の流れ\n","\n","本演習のように，機械学習を用いて予測モデルを構築し，未知の（テスト）データに対して予測を行う手順は，主に以下のようになります．\n","\n","1. データを用意し，特徴ベクトルを作る\n","2. どのような手法（モデル）を使うかを決める\n","3. モデルを学習する方法を決め，学習する\n","4. 未知のデータに予測を行う（そして本演習では提出する）\n"]},{"cell_type":"markdown","metadata":{"id":"uvBYZMeNZpbV"},"source":["## データ読み込み\n","演習で用いるデータはcsvファイル（comma-separated valuesファイル）で表現されています．\n","Pythonの標準の機能を使って読み込んでも良いのですが，Pythonには**pandasというデータ解析のための便利なライブラリ**があります．\n","pandasによって，CSVを含む様々なファイルを簡単に読み込み，さらに読み込んだデータに対して様々な処理を簡単に行うことができます．\n","\n","なお，今回は文字列の情報を含んでいるためpandasを用いますが，数値情報だけであれば，Pythonにおける**数値・行列・線形代数計算ライブラリのNumPy**で読み込んで処理するほうが楽であることも多いです（NumPyについては，day1_2_how_to_numpy.ipynbやday1_2_how_to_numpy_full.ipynbを参照）．\n","また，scikit-learnの関数には，NumPyの配列を前提とするものやNumPyの配列を返すものも数多くあります．そのため，今回の演習ではpandasで最低限の処理をした後，NumPyの配列に変換し（=いろいろな演算がサポートされている便利な配列），変換したものをscikit-learnに渡すことにします．\n","つまり，以下のような手順を行います：\n","1. `pandas`でデータを読み込む\n","2. `pandas`の便利な関数でごにょごにょして，`numpy`の`ndarray`（`array`）に変換\n","3. （場合によっては）`numpy`の便利な関数でごにょごにょして，特徴ベクトルを作成\n","4. scikit-learnに渡して学習\n","\n","まず，今回使うものを`import`（=C言語で言うところのincludeだと思ってください）をしましょう．"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"y0gicvqeZpbW","executionInfo":{"status":"ok","timestamp":1686588471284,"user_tz":-540,"elapsed":2197,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","# 機械学習のライブラリ．今回は線形回帰LinearRegressionを動かす．\n","# LinearRegressionはsklearnのlinear_modelモジュールの中にあるので，次のようにインポートする\n","from sklearn.linear_model import LinearRegression "]},{"cell_type":"markdown","metadata":{"id":"kYCQGaoMZpbZ"},"source":["上のセルを動かしましたか？その際に特にエラーが出なければ，インポートに成功しています．\n","これ以降皆さんはnumpy，pandas，そしてsklearn.linear_modelの`LinearRegression`が使えるようになりました！\n"]},{"cell_type":"markdown","metadata":{"id":"LtwO1bWzZpbZ"},"source":["では，次は訓練データとテストデータを読み込みます．\n","csvファイルは，pandasの`read_csv`という関数を使って読み込むことができます．\n","ファイルのパスを引数として渡すと，`pandas.DataFrame`という型で（オブジェクト指向言語なので，「`pandas.DataFrame`クラスのインスタンスを作成して」とも言える）読み込んだものを返してくれます．\n","詳細は[公式のドキュメント](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)を参照してください．\n","では実際に動かしてみます．\n","\n","このノートブックを動かしているディレクトリにdataディレクトリがあり，その中にtrain.csvとtest.csvが存在していると仮定しています．\n","そうでない場合は適宜書き換えてください．\n","\n","Goole Colabを用いている場合，Google Driveにdataフォルダを置いて，次のセルのコメントアウトを外して動かしてください（自身のPython環境で動かしている場合は，次のセルは飛ばして良いです）．次のセルを動かした後，以下の手順を踏むことでGoogle Driveのデータを読み込むことができるようになります．\n","- 以下のセルを動かすと，URLが出てくるのでそこにアクセスしてください．\n","- グーグルアカウントのログインが求められるので，ログインしてください．\n","- authorization codeが表示されるので，それを貼り付けてください．\n","- 更にその下のセルの`read_csv`で指定されているパスを適宜書き換えてください．画面左側のバーで「フォルダ」のタブを選ぶと\"drive\"というフォルダが出てくると思いますが，そこがGoogle Driveを表しています．そこを見て適宜パスを書き換えてください．"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"iGNrAnlNdW6P","outputId":"9468d062-f0b8-47b3-e620-06a8b05763c5","executionInfo":{"status":"ok","timestamp":1686588515309,"user_tz":-540,"elapsed":24796,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') # google driveをマウント（＝Colabから使えるようにする）"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"eeJHyc4tZpba","executionInfo":{"status":"ok","timestamp":1686588608155,"user_tz":-540,"elapsed":1244,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[],"source":["# 動的型付け言語なので，変数の型の宣言は不要\n","# Google Colabの場合\n","d_train = pd.read_csv(\"drive/My Drive/data/train.csv\") # 訓練データを読み込む．TFがGoogle Driveの一番上にdataディレクトリを置いた場合はこのようなパスになった\n","d_test = pd.read_csv(\"drive/My Drive/data/test.csv\") # テストデータを読み込む． TFがGoogle Driveの一番上にdataディレクトリを置いた場合はこのようなパスになった\n","# Jupyter Notebook の場合\n","#d_train = pd.read_csv(\"data/train.csv\") # 訓練データを読み込む\n","#d_test = pd.read_csv(\"data/test.csv\") # テストデータを読み込む\n"]},{"cell_type":"markdown","metadata":{"id":"NYspsl3KZpbc"},"source":["エラーが何も出ていなければ読み込めています．しかし言われるがまま読み込んだだけでどうなっているのかよくわかりませんね．`print`してみましょう．"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Dd5r2xjhZpbc","outputId":"5ac40df5-c43d-49c5-effd-bf213902f998","executionInfo":{"status":"ok","timestamp":1686588622494,"user_tz":-540,"elapsed":406,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["訓練データ\n","       Unnamed: 0        Date  AveragePrice        4046        4225  \\\n","0              32  2016-05-15          0.82  1134719.15   643464.88   \n","1              43  2016-02-28          0.89  1873878.11  2020327.87   \n","2              15  2017-09-17          2.94      181.23      861.34   \n","3              10  2018-01-14          0.81   628591.78   284087.44   \n","4              14  2017-09-24          1.57        1.21      105.02   \n","...           ...         ...           ...         ...         ...   \n","12769          47  2015-02-01          1.44     1565.49     4210.72   \n","12770          46  2016-02-07          1.07     7720.21    22562.00   \n","12771          43  2015-03-01          1.92      386.65     5898.07   \n","12772           9  2015-10-25          1.86      441.78     1817.74   \n","12773          28  2015-06-14          0.92  3239258.39  2416002.43   \n","\n","            4770  Small Bags  Large Bags  XLarge Bags          type  \\\n","0       95527.46   871562.92   104146.00     17435.17  conventional   \n","1      302210.56  2091747.51   282242.79     17870.86  conventional   \n","2           0.00      312.22     1020.40         0.00       organic   \n","3       15249.83   200603.91   221593.36      4786.66  conventional   \n","4           0.00    16555.36        0.00         0.00       organic   \n","...          ...         ...         ...          ...           ...   \n","12769       0.00     1133.33      756.16         0.00       organic   \n","12770      37.04    38739.27    11885.39         0.00       organic   \n","12771       0.00      516.67      372.96         0.00       organic   \n","12772      15.61       72.11      907.40         0.00       organic   \n","12773  112965.22   776961.13   214729.56        84.95  conventional   \n","\n","                   region  \n","0              LosAngeles  \n","1              California  \n","2                 Spokane  \n","3           PhoenixTucson  \n","4      NorthernNewEngland  \n","...                   ...  \n","12769             Atlanta  \n","12770          LosAngeles  \n","12771             Detroit  \n","12772        Philadelphia  \n","12773                West  \n","\n","[12774 rows x 11 columns]\n","\n","テストデータ\n","      Unnamed: 0        Date       4046       4225      4770  Small Bags  \\\n","0              3  2015-12-06    1358.53    1735.98      0.00      130.00   \n","1             25  2015-07-05    4890.33  119457.27  13495.86    30631.37   \n","2             40  2016-03-20  105069.07  352698.21   9425.64   252881.52   \n","3             16  2017-09-10     313.75    4230.58      0.00     2166.91   \n","4             10  2018-01-14    1527.63    2981.04    727.01    10919.54   \n","...          ...         ...        ...        ...       ...         ...   \n","5470          51  2017-01-08       0.00     113.63      0.00     1777.21   \n","5471          40  2017-03-26    5449.39   23565.89   1102.12    21163.88   \n","5472          15  2017-09-17   44304.44   81995.44   1367.96    70410.57   \n","5473          46  2015-02-08   17561.23    9396.92      0.00      598.61   \n","5474           0  2016-12-25    4349.63  346516.32   4183.69    91481.59   \n","\n","      Large Bags  XLarge Bags          type            region  \n","0        1175.74         0.00       organic           Atlanta  \n","1       21037.53      1204.07  conventional      Indianapolis  \n","2      325375.97         0.00       organic           TotalUS  \n","3        3172.35         0.00       organic  CincinnatiDayton  \n","4          50.00         0.00       organic  WestTexNewMexico  \n","...          ...          ...           ...               ...  \n","5470      552.73         0.00       organic          Syracuse  \n","5471    30701.49         0.00       organic            Plains  \n","5472     2293.63       260.57  conventional   RichmondNorfolk  \n","5473        0.00         0.00       organic      SanFrancisco  \n","5474     1069.52         0.00  conventional            Boston  \n","\n","[5475 rows x 10 columns]\n"]}],"source":["print(\"訓練データ\")\n","print(d_train)\n","print(\"\\nテストデータ\")\n","print(d_test)"]},{"cell_type":"markdown","metadata":{"id":"4TP1btArZpbg"},"source":["train.csvの中身が出てきました！すばらしいですね．\n","詳細はスライドを確認してほしいですが，この行列は，各行が一つのアボカドのデータに対応しています．\n","各列はアボカドの何らかの情報を表していて，各列がどのような情報なのかはヘッダーに書かれています．\n","たとえば，1列目は\"Date\"と書かれているので，これは日付の情報ですね．\n","訓練データの最後の列は\"AveragePrice\"と書かれており，これはまさしく目標値（出力・教師情報）です．\n","テストデータに\"AveragePrice\"の列はなく，この列の値を予測して，その予測の正確さで皆さんに競っていただくのがこのコンペティションです．\n","\n","\n","さて，予測モデルを動かす前に，ちょっと`d_train`で遊んでみます．各列や行を取り出してみましょう．\n","\n","列を取り出すのは非常に簡単で，他のプログラミング言語で配列の要素にアクセスするのと同じようにブラケット（角括弧）を用います．具体的には，\n","\n","d_train[列の名前]\n","\n","とすることで取り出せます．また，複数の列を取り出すことは，\n","\n","d_train[列の名前のリスト]\n","\n","でできます（\"取り出す\"と言っていますが，元の`DataFrame`から消えるわけではありません）．以下のセルで実際にやってみましょう．"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"4a4PBglyZpbg","outputId":"bad3963b-fe59-46a3-cc5e-9d1e78778d44","executionInfo":{"status":"ok","timestamp":1686588637030,"user_tz":-540,"elapsed":356,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["値段の列を取り出す\n","0        0.82\n","1        0.89\n","2        2.94\n","3        0.81\n","4        1.57\n","         ... \n","12769    1.44\n","12770    1.07\n","12771    1.92\n","12772    1.86\n","12773    0.92\n","Name: AveragePrice, Length: 12774, dtype: float64\n","\n","オーガニック否かと地域を取り出す\n","               type              region\n","0      conventional          LosAngeles\n","1      conventional          California\n","2           organic             Spokane\n","3      conventional       PhoenixTucson\n","4           organic  NorthernNewEngland\n","...             ...                 ...\n","12769       organic             Atlanta\n","12770       organic          LosAngeles\n","12771       organic             Detroit\n","12772       organic        Philadelphia\n","12773  conventional                West\n","\n","[12774 rows x 2 columns]\n","\n","取り出した結果を別の変数に格納することもできる\n","0        2016-05-15\n","1        2016-02-28\n","2        2017-09-17\n","3        2018-01-14\n","4        2017-09-24\n","            ...    \n","12769    2015-02-01\n","12770    2016-02-07\n","12771    2015-03-01\n","12772    2015-10-25\n","12773    2015-06-14\n","Name: Date, Length: 12774, dtype: object\n"]}],"source":["print(\"値段の列を取り出す\")\n","print(d_train['AveragePrice'])\n","\n","print(\"\\nオーガニック否かと地域を取り出す\")\n","print(d_train[[\"type\", \"region\"]])\n","\n","print(\"\\n取り出した結果を別の変数に格納することもできる\")\n","d_train_date = d_train[\"Date\"]\n","print(d_train_date)\n"]},{"cell_type":"markdown","metadata":{"id":"zWVB37qGZpbi"},"source":["とりだせました！すばらしいですね．\n","\n","次に行を取り出してみましょう．行も列と同様にブラケット（角括弧）で取り出せます．d_train\\[i:j\\]とすることで，i行目からj-1行目の値を取り出すことができます．"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"oluL21z-Zpbj","outputId":"f6e0e3ba-5e28-44fd-b5e2-3420f1179e3c","executionInfo":{"status":"ok","timestamp":1686588641007,"user_tz":-540,"elapsed":293,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0から4-1行目まで取り出す\n","   Unnamed: 0        Date  AveragePrice        4046        4225       4770  \\\n","0          32  2016-05-15          0.82  1134719.15   643464.88   95527.46   \n","1          43  2016-02-28          0.89  1873878.11  2020327.87  302210.56   \n","2          15  2017-09-17          2.94      181.23      861.34       0.00   \n","3          10  2018-01-14          0.81   628591.78   284087.44   15249.83   \n","\n","   Small Bags  Large Bags  XLarge Bags          type         region  \n","0   871562.92   104146.00     17435.17  conventional     LosAngeles  \n","1  2091747.51   282242.79     17870.86  conventional     California  \n","2      312.22     1020.40         0.00       organic        Spokane  \n","3   200603.91   221593.36      4786.66  conventional  PhoenixTucson  \n","\n","10行目だけ取り出す\n","    Unnamed: 0        Date  AveragePrice  4046   4225  4770  Small Bags  \\\n","10          40  2017-03-26          2.12   0.0  137.6   0.0      753.67   \n","\n","    Large Bags  XLarge Bags     type    region  \n","10     1722.88          0.0  organic  Syracuse  \n"]}],"source":["print(\"0から4-1行目まで取り出す\")\n","print(d_train[0:4])\n","print(\"\\n10行目だけ取り出す\")\n","print(d_train[10:11])"]},{"cell_type":"markdown","metadata":{"id":"hDEiokw_Zpbl"},"source":["できました．素晴らしいですね！他にも色々できますし，同じことを行う別の方法があったりもしますが，今回はとりあえずこの程度にしておきましょう．\n","詳細は例えばhttps://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html 等を見てみてください．"]},{"cell_type":"markdown","metadata":{"id":"7n7okSAnZpbm"},"source":["さて，次に特徴ベクトルを作っていきたいのですが，その前にいくつかの変数を準備します．\n","\n","まず，訓練データとテストデータの数を表す変数`n_train`と`n_test`を準備します．今日は（最後の発展的なQuiz 3以外では）使いませんが，今後よく使うためここで取得の仕方を確認しておきます．\n","各行が一つのデータに対応しているので，**`d_train`や`d_test`の行の数**が取得できればよいのですが，これは`len`関数によって取得できます．\n","\n","また，sklearnでモデルを学習させる際に必要となるので，訓練データの目標値\"AveragePrice\"を`d_train`から取り出して分離させておきます．\n","`pop`メソッドを使うことで，`DataFrame`（`d_train`や`d_test`）から特定の列を分離させることができます．\n","「分離」と言っている通り，ブラケットによるアクセスと違い，`pop`で取り出すと**元の`DataFrame`からその列は削除されます**．"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"IdRqhaBCZpbm","outputId":"f4ceeb9f-b566-46ea-a1b6-a3b2aa05ce3b","executionInfo":{"status":"ok","timestamp":1686588644523,"user_tz":-540,"elapsed":497,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["訓練データとテストデータの数を取得\n","訓練データ数：12774，テストデータ数：5475\n","\n"," 出力情報を取り出す．AveragePriceの列が消えている\n","       Unnamed: 0        Date        4046        4225       4770  Small Bags  \\\n","0              32  2016-05-15  1134719.15   643464.88   95527.46   871562.92   \n","1              43  2016-02-28  1873878.11  2020327.87  302210.56  2091747.51   \n","2              15  2017-09-17      181.23      861.34       0.00      312.22   \n","3              10  2018-01-14   628591.78   284087.44   15249.83   200603.91   \n","4              14  2017-09-24        1.21      105.02       0.00    16555.36   \n","...           ...         ...         ...         ...        ...         ...   \n","12769          47  2015-02-01     1565.49     4210.72       0.00     1133.33   \n","12770          46  2016-02-07     7720.21    22562.00      37.04    38739.27   \n","12771          43  2015-03-01      386.65     5898.07       0.00      516.67   \n","12772           9  2015-10-25      441.78     1817.74      15.61       72.11   \n","12773          28  2015-06-14  3239258.39  2416002.43  112965.22   776961.13   \n","\n","       Large Bags  XLarge Bags          type              region  \n","0       104146.00     17435.17  conventional          LosAngeles  \n","1       282242.79     17870.86  conventional          California  \n","2         1020.40         0.00       organic             Spokane  \n","3       221593.36      4786.66  conventional       PhoenixTucson  \n","4            0.00         0.00       organic  NorthernNewEngland  \n","...           ...          ...           ...                 ...  \n","12769      756.16         0.00       organic             Atlanta  \n","12770    11885.39         0.00       organic          LosAngeles  \n","12771      372.96         0.00       organic             Detroit  \n","12772      907.40         0.00       organic        Philadelphia  \n","12773   214729.56        84.95  conventional                West  \n","\n","[12774 rows x 10 columns]\n","0        0.82\n","1        0.89\n","2        2.94\n","3        0.81\n","4        1.57\n","         ... \n","12769    1.44\n","12770    1.07\n","12771    1.92\n","12772    1.86\n","12773    0.92\n","Name: AveragePrice, Length: 12774, dtype: float64\n","y_trainのクラスは<class 'pandas.core.series.Series'>\n"]}],"source":["print(\"訓練データとテストデータの数を取得\")\n","n_train = len(d_train)\n","n_test = len(d_test)\n","print(f\"訓練データ数：{n_train}，テストデータ数：{n_test}\")\n","print(\"\\n 出力情報を取り出す．AveragePriceの列が消えている\")\n","# targetの値\n","y_train = d_train.pop('AveragePrice')\n","print(d_train)\n","print(y_train)\n","print(f\"y_trainのクラスは{type(y_train)}\")"]},{"cell_type":"markdown","metadata":{"id":"7R0dhDE1Zpbo"},"source":["訓練データ数は`12774`，テストデータ数は`5475`で，これはスライドやコンペサイトに書いてあるとおりです．\n","また，`d_train`から\"AveragePrice\"の列が消えていて，`y_train`が\"AveragePrice\"の情報を持っていますね．\n","\n","今，`y_train`は怪しい（？）クラスのインスタンスになっています．別にこのままでもよいのですが，後々のことを考えると，NumPyの配列の方が都合が良いです．\n","便利なことに，`y_train.values`とすることで，列の名前や行の番号が消え，実際に持っている値だけをNumPyの配列として取り出すことができます．\n","`y_train`は`Series`クラスのインスタンスになっていますが，これは`DataFrame`クラスでも同じです．\n","つまり，`d_train.values`とすることで，同じく行番号や列の名前を消して，中の値だけをNumPyの配列として取り出すことができます．"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"UL-mhIA0Zpbp","outputId":"c97983e2-ef4b-4f8c-b50a-7768e291b7ea","executionInfo":{"status":"ok","timestamp":1686588649057,"user_tz":-540,"elapsed":280,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.82 0.89 2.94 ... 1.92 1.86 0.92]\n","y_trainのクラスは<class 'numpy.ndarray'>\n"]}],"source":["y_train = y_train.values\n","print(y_train)\n","print(f\"y_trainのクラスは{type(y_train)}\")"]},{"cell_type":"markdown","metadata":{"id":"KEcnW_TBZpbr"},"source":["### ここまでのまとめ\n","- `pandas`の`read_csv`でcsvファイルを読み込むことができる．読み込んだファイルは`DataFrame`クラスのインスタンスとして返される．\n","- `DataFrame`クラスのインスタンスは`print`で中身を簡単にわかりやすく見ることができる．\n","- `DataFrame`では，[列の名前]や[列のリスト]とすることで，特定の列を取り出すことができる．\n","- `DataFrame`では，[i:j]とすることで，特定の範囲の行を取り出すことができる．\n","- `.values`で`DataFrame`や`DataFrame`から取り出した列の持つ値を，NumPyの配列`np.array`として取り出すことができる．"]},{"cell_type":"markdown","metadata":{"id":"9d8mZ0s9Zpbr"},"source":["## 特徴ベクトルを作る"]},{"cell_type":"markdown","metadata":{"id":"LV6gQ_N8Zpbs"},"source":["さて，いよいよ特徴ベクトルを作っていきましょう．入力の情報として，以下が与えられています：\n"," - Date：日付\n"," - 4046, 4225, 4770：小，大，特大として売れた数\n"," - Small Bags, Large Bags, XLarge Bags：小，大，特大の袋として売れた数\n"," - type：オーガニックか否か\n"," - region：地域\n","\n","この中で，\"Date\"，\"type\"，\"region\"が文字列（string)の情報です．\n","しかし，機械学習のアルゴリズムの多くは各データが「数値のベクトル」として表されていると仮定しており，このような**文字列の情報はそのまま扱えません**．\n","今回動かしてみる線形回帰も，数値の情報しか扱えません．\n","機械学習や統計では，（基本的には）**一つ一つのデータは数ベクトル**として表現され，**データの集まりは数の行列**として表現されている，と考えます（一つ一つの行が一つのデータに対応し，一つ一つの列が何らかの情報（特徴）に対応）．同様に，**訓練データの目標値（ここではAveragePrice）の集まりは数のベクトル**として表現されていると考えます．\n","sklearnを使って学習する際も，訓練データの入力を表す行列と，訓練データの目標値を表すベクトルを渡す必要があります．\n","\n","ここまででも結構な分量になっている気がするので，今回は，\"4046\"，\"4225\"，\"4770\"，\"Small Bags\"，\"Large Bags\"，\"XLarge Bags\"の**元から数値的な情報である6つだけ**を用いることにします．\n","\"Date\"，\"type\"，\"region\"の文字列で表される情報は次回用いることにします（もちろん，どのように用いるかのアイデアがすでにあり，そのためのプログラムが書けそうであるならば，ぜひ行ってみてください）．\n","\n","\n","ここまで皆さんは**ただ読んで動かしてきただけで退屈**だったかと思います．**そこでQuizです**．"]},{"cell_type":"markdown","metadata":{"id":"zTB3V5_1Zpbs"},"source":["### Quiz 1\n","\n","以下のセルを完成させて，`d_train`と`d_test`から\"4046\"，\"4225\"，\"4770\"，\"Small Bags\"，\"Large Bags\"，\"XLarge Bags\"の6つの列を取り出して作った，`X_train_num`と`X_test_num`を作成しなさい．ここで，`X_train_num`と`X_test_num`はどちらもNumPyの配列`np.ndarray`（`np.array`）であるとします．\n","なお，`columns_num`は負担を削減するためこちらで用意したリストです．使わなくても良いですが，使ったほうが楽かと思います．\n","\n","**Quizの解答はノートブックの最下部にあります．**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8jHiGdZZpbs"},"outputs":[],"source":["columns_num = [\"4046\", \"4225\", \"4770\", \"Small Bags\", \"Large Bags\", \"XLarge Bags\"]\n","X_train_num = \n","X_test_num = "]},{"cell_type":"markdown","metadata":{"id":"59ceiNQUZpbu"},"source":["できたでしょうか？中身を出力してみます．上の`d_train`や`d_test`と見比べてみてください．\n","`type`や`shape`の`print`では，\n"," - 訓練データ：<class 'numpy.ndarray'> (12774, 6)\n"," - テストデータ：<class 'numpy.ndarray'> (5475, 6)\n"," \n","と表示されていればよいです（`.shape`は配列の形を表しています）．"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"fQ1_EuVmZpbv","outputId":"d4801698-bc27-4635-fd06-d10fa5e3202a","executionInfo":{"status":"ok","timestamp":1686588751891,"user_tz":-540,"elapsed":334,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train_numを表示\n","<class 'numpy.ndarray'> (12774, 6)\n","[[1.13471915e+06 6.43464880e+05 9.55274600e+04 8.71562920e+05\n","  1.04146000e+05 1.74351700e+04]\n"," [1.87387811e+06 2.02032787e+06 3.02210560e+05 2.09174751e+06\n","  2.82242790e+05 1.78708600e+04]\n"," [1.81230000e+02 8.61340000e+02 0.00000000e+00 3.12220000e+02\n","  1.02040000e+03 0.00000000e+00]\n"," ...\n"," [3.86650000e+02 5.89807000e+03 0.00000000e+00 5.16670000e+02\n","  3.72960000e+02 0.00000000e+00]\n"," [4.41780000e+02 1.81774000e+03 1.56100000e+01 7.21100000e+01\n","  9.07400000e+02 0.00000000e+00]\n"," [3.23925839e+06 2.41600243e+06 1.12965220e+05 7.76961130e+05\n","  2.14729560e+05 8.49500000e+01]]\n","\n","X_test_numを表示\n","<class 'numpy.ndarray'> (5475, 6)\n","[[1.3585300e+03 1.7359800e+03 0.0000000e+00 1.3000000e+02 1.1757400e+03\n","  0.0000000e+00]\n"," [4.8903300e+03 1.1945727e+05 1.3495860e+04 3.0631370e+04 2.1037530e+04\n","  1.2040700e+03]\n"," [1.0506907e+05 3.5269821e+05 9.4256400e+03 2.5288152e+05 3.2537597e+05\n","  0.0000000e+00]\n"," ...\n"," [4.4304440e+04 8.1995440e+04 1.3679600e+03 7.0410570e+04 2.2936300e+03\n","  2.6057000e+02]\n"," [1.7561230e+04 9.3969200e+03 0.0000000e+00 5.9861000e+02 0.0000000e+00\n","  0.0000000e+00]\n"," [4.3496300e+03 3.4651632e+05 4.1836900e+03 9.1481590e+04 1.0695200e+03\n","  0.0000000e+00]]\n"]}],"source":["print(\"X_train_numを表示\")\n","print(type(X_train_num), X_train_num.shape)\n","print(X_train_num)\n","print(\"\\nX_test_numを表示\")\n","print(type(X_test_num), X_test_num.shape)\n","print(X_test_num)"]},{"cell_type":"markdown","metadata":{"id":"4SqDf0uWZpbx"},"source":["なお，この配列はそれぞれ列の数が6つ，つまり各データが6つの数値的な情報によって表現されている，ということになります．\n","このようなデータを表す情報のことを**特徴(feature)**といい，特徴のベクトルのことをそのまま**特徴ベクトル**，特徴の数を**（データの，あるいは特徴の）次元**と言います（つまり，今は6次元の特徴ベクトルとしてデータを表現している，といえる）．"]},{"cell_type":"markdown","metadata":{"id":"qVKtGgAyZpby"},"source":["## 線形回帰を動かす\n","ここまでおつかれさまでした．**ついに機械学習アルゴリズムを動かす**ときが来ました．\n","sklearnの教師あり学習のモデル・アルゴリズムの実装について，以下に列挙されています：\n","\n","https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n","\n","凄まじい量ですね．色々ありますが，最も単純な手法の一つである**線形回帰（重回帰）=LinearRegression**を動かしてみます．\n","\n","一応，線形回帰について簡単に説明しておきます．まず，**線形モデル（Linear Model）**は以下のようなモデルです：\n","\n","$$\n"," y(\\mathbf{x}; \\mathbf{w}) = \\mathbf{w}^{\\top} \\mathbf{x} = \\sum_{j=1}^{D}w_jx_j,\n","$$\n","\n","\n","ここで，$\\mathbf{x} \\in \\mathbb{R}^{D}$は特徴ベクトル，$D$はその次元（今回の例だと$D=6$），$\\mathbf{w} \\in \\mathbb{R}^{D}$は線形モデルの学習されるパラメータです（$x_1$や$x_2$というのが一つの特徴を表しています）．\n","「**線形モデルの学習**」は「**訓練データから$\\mathbf{w}$をイイカンジに定める**」ことを意味します．\n","線形モデルを回帰に用いるとき，あるいは**平均二乗誤差**$\\sum_{n=1}^N (y(\\mathbf{x}_n; \\mathbf{w})-t_n)^2 / N$を最小化することで学習を行うとき（特にデータサイエンスの講義で習った方法で（初回の「問題」）行うとき），線形モデルは特に**線形回帰**と呼ばれます．\n","データサイエンスの初回で導入された**多項式回帰**も結局のところ線形回帰とみなすことができます（多項式特徴ベクトルに対する線形回帰）．\n","\n","**線形モデル**の学習アルゴリズムは一つではなく様々あります．\n","線形回帰では二乗誤差を最小化しましたが，別の関数を最小化しても良いです．\n","また，同じ関数を最小化する場合でも，最小化の仕方（アルゴリズム）も一つとは限りません．\n","また，「何らかの制約を課せられた線形モデル」というのもあったりします．\n","「二乗誤差を用いた線形モデル」が「線形回帰」と呼ばれるように，学習アルゴリズムが変わるとまた別の名前で呼ばれるようになったりします．\n","[先程のsklearnの教師あり学習のモデル・アルゴリズムの実装一覧](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning)を見ると，**Linear Models**に属している手法が**合計で17個**もありますが，これらは基本的には全てモデル（関数の形）としては同じだけれども，学習アルゴリズム等が違うため分けられています．\n","\n","\n","線形回帰の学習方法についてはデータサイエンスの授業で習い，実験で実際に定める（学習する）プログラムを書くことになりますが，今回の演習ではあくまでデータ分析全体の流れを理解することなので，学習するプログラムを皆さんに書いてもらうことはありません（もちろん，勉強のために書くことは素晴らしいことだと思いますが）．偉大なるsklearnが勝手にやってくれるのです．"]},{"cell_type":"markdown","metadata":{"id":"G9-gGQynZpby"},"source":["ちょっと話が長くなってしまいました．本題に入ります．`LinearRegression`を使えば線形回帰を動かすことができます．\n","sklearnを用いる基本的な手順は，\n","1. モデルのインスタンスを作成\n","2. 作成したモデルオブジェクトを**`fit`メソッド**を用いて学習．`fit`メソッドには訓練データの入力と目標値（つまり，行列とベクトル）を渡す．\n","3. 学習したモデルを用いて**`predict`メソッド**で予測．`predict`メソッドにはデータの入力（つまり行列）を渡す．\n","\n","となっています．スライドでは，プロセスの中に「学習アルゴリズムを選ぶ」というような手順が入っていたと思います．\n","sklearnでは学習アルゴリズムが違う場合は別のクラスとして提供されていることが多いです（先程の線形モデルの例のように）．\n","また，一つのクラスの中で学習アルゴリズムを選べる場合も，インスタンスを作成する時に学習アルゴリズムを指定します．\n","したがって，sklearnでは「モデルのインスタンスを作成」した時点で学習アルゴリズムを選んだことになります．\n","\n","\n","では実際に上の手順通りに学習してみます．\n","Pythonにおいて，`ClassA`という名前のクラスのインスタンスは`ClassA()`で作ることができるのでした（day1_how_to_python.ipynb参照）．\n","したがって，今回のケースでは以下のようになります．"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"-Th3rbQ9Zpby","executionInfo":{"status":"ok","timestamp":1686588759378,"user_tz":-540,"elapsed":4,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[],"source":["# 手順1：LinearRegressionのインスタンスの作成\n","lr = LinearRegression()\n","# 手順2：上で作ったオブジェクトの学習\n","lr.fit(X_train_num, y_train)\n","# 手順3：テストデータに対する予測\n","y_pred_test = lr.predict(X_test_num)"]},{"cell_type":"markdown","metadata":{"id":"mCLt1jO5Zpb0"},"source":["**これで学習とテストデータに対する予測まで終わりました!**たった3行です．すごいですね．予測結果をプリントしてみましょう．"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"0Ir7QAShZpb1","outputId":"4e6bd93d-a38a-46cf-e166-ff5aa60af0f5","executionInfo":{"status":"ok","timestamp":1686588762264,"user_tz":-540,"elapsed":331,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[1.42066402 1.42219244 1.39648389 ... 1.42335768 1.41967346 1.4463927 ]\n"]}],"source":["print(y_pred_test)"]},{"cell_type":"markdown","metadata":{"id":"wdEGyWkVZpb3"},"source":["## 予測結果の提出"]},{"cell_type":"markdown","metadata":{"id":"T0jer0SFZpb4"},"source":["予測ができたので，この結果を提出することを考えます．予測結果をファイルに出力しなければなりません．ファイル出力ときくと面倒そうだと思うかもしれませんが，NumPyを用いれば以下のように簡単にできます．\n","`np.savetxt`の`X`という引数で保存したい配列を指定し，`fname`という引数でファイル名を指定します．\n","今回は，`y_pred_test`を`y_pred_lr.txt`という名前で保存することにします．"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"I-vIgkJLZpb4","executionInfo":{"status":"ok","timestamp":1686588767175,"user_tz":-540,"elapsed":281,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[],"source":["np.savetxt(X=y_pred_test, fname='y_pred_lr.txt')"]},{"cell_type":"markdown","metadata":{"id":"MERRXZkFZpb6"},"source":["y_pred_lr.txtというファイルが生成されました（Google Colabの場合は，画面左側のタブが「ファイル」のであるとき，「ファイル」という文字の下に3つアイコンがありますが，その真ん中の「更新」アイコンを押すと出てくるはずです）．これを提出してみる（Google Colabの場合はまず生成されたy_pred_lr.txtをダウンロードしてください）と，全てが1.0のy_pred_example.txtより良い結果になると考えられます（ちゃんと学習ができていれば）．"]},{"cell_type":"markdown","metadata":{"id":"S0e2FUtPZpb6"},"source":["## 線形回帰の修正\n","\n","線形モデルは以下の式\n","\n","$$\n"," y(\\mathbf{x}; \\mathbf{w}) = \\mathbf{w}^{\\top} \\mathbf{x} = \\sum_{j=1}^{D}w_jx_j\n","$$\n","\n","で表される，と述べました．あきらかに，どのような$\\mathbf{w}$を推定（学習）しても，$\\mathbf{x}=\\mathbf{0}$のとき予測結果は$0$となってしまいます．\n","一次元の場合で考えるとわかりやすいです：このモデルは**原点を通る直線**しか表現することができません．\n","そこで，以下のように新たに**バイアス項（bias term）**あるいは**切片（intercept）**と呼ばれるパラメータ$b \\in \\mathbb{R}$を導入することがあります：\n","\n","$$\n"," y(\\mathbf{x}; \\mathbf{w}, b) = \\mathbf{w}^{\\top} \\mathbf{x} + b= \\sum_{j=1}^{D}w_jx_j + b.\n","$$\n","\n","$b$も$\\mathbf{w}$と同様に学習するパラメータです．\n","\n","$b$を導入したほうが良いのか否かはタスクやデータに依存しており，それ自体は学習するものではなく，**機械学習のユーザが決める**ものです．\n","機械学習のモデルや学習アルゴリズムの中には，このように**学習するのではなくユーザが定める要素**を持つものがあります（今回は「用いるか否か」ですが，連続値や離散値を定めないといけないこともある）．\n","このような要素（パラメータ）を**ハイパーパラメータ**と言います（もっとも，今回の例では「用いるか否か」であるためあまり**パラメータ感がない**上に，さらに$b=0$と推定されれば「用いない」に対応するため，あまりハイパーパラメータとは感じない（もしかすると言わない）かもしれませんが）．\n","わかりやすいハイパーパラメータの例としては，データサイエンスの初回の授業で出てきた，**正則化項の強さ$\\lambda$**があげられます．\n","\n","さて，この話を聴くと**$b$を導入するぞ！**と思うのではないでしょうか．\n","しかし，**実はsklearnの`LinearRegression`ではデフォルトで導入**されています．\n","そこで，今度は**$b$を導入しない**ことを考えてみます．\n","sklearnにおいて，モデルのハイパーパラメータはインスタンスを作る際に指定することができます．\n","ではここでQuizです．"]},{"cell_type":"markdown","metadata":{"id":"X0fqTBOjZpb7"},"source":["### Quiz 2\n","[sklearnのLinearRegressionのドキュメント](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)を読んで，「**バイアス項（切片）を使わない線形回帰**」を動かし，学習しなさい．また，テストデータに関する予測結果を`print`し，バイアス項を使った場合（つまり，上の`y_pred_lr`の`print`結果）と結果が変わっていることを確認しなさい．さらに，その予測結果を`y_pred_lr_without_bias.txt`として保存しなさい（提出はしてもしなくてもよい）．"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"id":"hdP7zJznZpb7","outputId":"c09b92ba-53e0-48a2-8efc-d82627b89c73"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 0.10116005  0.03665987 -0.00890221 ...  0.00281757  0.71213428\n","  0.00324945]\n"]}],"source":[]},{"cell_type":"markdown","metadata":{"id":"2mh_BzLyZpb9"},"source":["バイアス項を導入した場合（最初に動かした結果）と比べると，予測の値が全体的にかなり小さくなっていますね．\n","訓練データのAveragePriceと比較すると，この結果は一見すると良さそうには思えません．しかし，**良いか悪いかをパっと見ではなく定量的に評価する必要が本来はあります**．\n","提出するとスコアが返ってくるので定量的な評価をすることができますが，一日の提出回数が5回に限られているため，一見すると悪そうなものに5回のうちの1回を使ってしまうのはMOTTAINAI気もします．\n","**提出をする前の定量的な評価**についても次回学んでいきましょう．\n","\n","今日の資料はここで終了です．おつかれさまでした．\n","上で述べていますが，sklearnには他にも様々なモデル・アルゴリズムが実装されているので，時間があればぜひ色々試してみてください（授業資料は最低限の手引きくらいの気持ちで）．LinearRegressionだけでもあと一つくらいはいじるパラメータがあると思います．\n","やる気のある方はぜひ金曜日以外も積極的に取り組んでみてください．\n"]},{"cell_type":"markdown","metadata":{"id":"zsEO5dR4Zpb-"},"source":["## まとめその2\n"," - 機械学習のアルゴリズムは（基本的には）数値の情報しか使えない．非数値的な情報はどうにかして数的な情報に変換する必要がある．\n"," - sklearnでは以下の手順で予測モデルを作成，学習しテストデータの予測を行う：(1)インスタンスを作成し，(2)`fit`メソッドでモデルを学習，(3)`predict`メソッドでテストデータの目標値を予測．\n"," - `np.savetxt`で予測結果をファイルに書き込むことができる．\n"," - 多くの予測モデルにはユーザが決めるパラメータがあり，それらをハイパーパラメータという．ハイパーパラメータの値によって結果は大きく変わることもあるため，試行錯誤の余地がある．\n"," - 「文字列の特徴をどうするか」「提出をする前の定量的な評価」については次回を行う ．"]},{"cell_type":"markdown","metadata":{"id":"_sT_CfDYZpb-"},"source":["### Quiz 3 (すこし発展的）\n","情報理工学演習IVの担当教員とTA/TFは，バイアス項付きの線形回帰にひどい恨みがあるようで，**バイアス項付きの設定の`LinearRegression`を使うことを禁止してしまった（注意：してませんが，仮定の話です）**．\n","しかし，あなたには複雑な事情があり，どうしても，なにがなんでも，どんなことをしてでも**バイアス項付きの線形回帰を使いたい**．\n","そこで，バイアス項を使わない設定の`LinearRegression`（つまり，Quiz 2のときの設定の`LinearRegression`のインスタンス）で，**工夫を凝らして**，バイアス項付きの線形モデル（つまり，最初に動かした線形モデル`lr=LinearRegression()`）と同じ予測を行えるようにしなさい．"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"EEHoQXX9Zpb-","outputId":"9be439f4-7418-43bd-9d88-dd3305952d89"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.42770035 1.42778589 1.41099591 ... 1.42480144 1.52284404 1.42431654]\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hIb9-Ov_ZpcA"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hPSU2vf2ZpcD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-tMDSNdzZpcE"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3WedY7N7ZpcG"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cDMa9eQfZpcI"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xXr9itgmZpcK"},"source":["## Answers "]},{"cell_type":"markdown","metadata":{"id":"669YHjN7ZpcK"},"source":["### Quiz 1\n","`DataFrame`に対して，ブラケット（角括弧）[]を使うことで特定の列を取り出せるのでした．また，`.values`で`DataFrame`の値のみを持つ`np.array`を作成できるのでした．"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"z5kZ3j5fZpcL","executionInfo":{"status":"ok","timestamp":1686588741921,"user_tz":-540,"elapsed":276,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[],"source":["columns_num = [\"4046\", \"4225\", \"4770\", \"Small Bags\", \"Large Bags\", \"XLarge Bags\"]\n","X_train_num = d_train[columns_num].values\n","X_test_num = d_test[columns_num].values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q99oC3o7ZpcN"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iG6R5X4aZpcP"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BrG6QEluZpcQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtlX2w9jZpcS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lEwgU9JCZpcU"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2397lSpZpcX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RPX5B6s1ZpcY"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"nfgdwC6OZpca"},"source":["### Quiz 2"]},{"cell_type":"markdown","metadata":{"id":"uUtxk9ltZpca"},"source":["`LinearRegression`のドキュメントを見ると，`fit_intercept`というパラメータがあり，以下のように説明がされています：\"Whether to calculate the intercept for this model.\"\n","そのため，`fit_intercept=False`を，インスタンスを作る時に指定してあげればよいです．ファイルの作成には`np.savetxt`を使うのでした．"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"2iHXz7CBZpcb","outputId":"2fa29f67-c379-4e2d-c5a3-b524136f7c9d","executionInfo":{"status":"ok","timestamp":1686588866160,"user_tz":-540,"elapsed":275,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[ 0.00021382  0.03226085  0.16998403 ...  0.03687215 -0.0010252\n","  0.10894106]\n"]}],"source":["lr = LinearRegression(fit_intercept=False)\n","lr.fit(X_train_num, y_train)\n","y_pred_test_without_bias = lr.predict(X_test_num)\n","print(y_pred_test_without_bias)\n","np.savetxt(X=y_pred_test_without_bias, fname='y_pred_lr_without_bias.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C4jxfBXwZpcd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8sRPIAcZpce"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5f28JwOgZpcg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kIXXo-cZpci"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gkzOrvoJZpcj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RTykxfKRZpcl"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fsPb_tSIZpcn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"2n3qZefKZpcq"},"source":["### Quiz 3\n","バイアス項付きの線形回帰は，\n","$$\n"," y(\\mathbf{x}; \\mathbf{w}, b) = \\mathbf{w}^{\\top} \\mathbf{x} + b= \\sum_{j=1}^{D}w_jx_j + b =  \\sum_{j=1}^{D}w_jx_j + b\\cdot 1\n","$$\n","と書けます（$b=b\\times 1$とした）．この$1$を**特徴の値**とみなすと，このバイアス項付きの線形回帰は次のように**バイアス項のない線形回帰**として書けます：\n","$$\n"," y(\\mathbf{x}; \\mathbf{w}, b) = y((x_1, \\ldots, x_D, 1)^\\top; (w_1, \\ldots, w_D, b)^\\top).\n","$$\n","つまり，「入力が$(x_1, \\ldots, x_{D}, 1)^\\top$の$D+1$次元ベクトルである，バイアス項なしの線形モデルのパラメータ$\\mathbf{w} \\in \\mathbb{R}^{D+1}$の$D+1$番目の要素」が，「入力が$\\mathbf{x}$であるバイアス項付きの線形回帰のバイアス項」に対応します．\n","したがって，`X_train_num`と`X_test_num`の列の末尾に（正確には，共通の位置ならどこでも良い）にすべてが**$1$の列ベクトル**を追加すれば良いです．\n","\n","`np.ndarray`の横方向の連結は`np.hstack`で行うことができます．すべてが`1`のベクトルや行列は`np.ones`で作成することができます．\n","[hstackの使い方](https://numpy.org/doc/stable/reference/generated/numpy.hstack.html)，[onesの使い方](https://numpy.org/doc/1.18/reference/generated/numpy.ones.html)はそれぞれのドキュメントや前回の資料を参照のこと．\n","結局，以下のようになります．"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"uhHFYsOhZpcr","outputId":"0c858c59-3baf-44c4-b015-d0c1aa50060b","executionInfo":{"status":"ok","timestamp":1686588871778,"user_tz":-540,"elapsed":309,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[1.42066402 1.42219244 1.39648389 ... 1.42335768 1.41967346 1.4463927 ]\n"]}],"source":["X_train_num_hstack1 = np.hstack([X_train_num, np.ones((n_train, 1))]) # 列の数が6から7になり，最後の列がすべて1\n","X_test_num_hstack1 = np.hstack([X_test_num, np.ones((n_test, 1))]) # 列の数が6から7になり，最後の列がすべて1\n","lr = LinearRegression(fit_intercept=False) # fit_intercept=Falseとすることを忘れないように！\n","lr.fit(X_train_num_hstack1, y_train) # 新しく作った行列を使う\n","y_pred_test = lr.predict(X_test_num_hstack1) # 新しく作った行列を使う\n","print(y_pred_test)"]},{"cell_type":"markdown","metadata":{"id":"QOJgZulVk7bb"},"source":["なお，sklearnには`add_dummy_feature`という関数があり，それを用いるとより簡単にできます．以下のようになります．"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"g4kLphaRZpcw","outputId":"e8f46633-781a-400c-afbf-e8c64d466f5b","executionInfo":{"status":"ok","timestamp":1686588876265,"user_tz":-540,"elapsed":402,"user":{"displayName":"野田五十樹","userId":"02013258251721762757"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[1.42066402 1.42219244 1.39648389 ... 1.42335768 1.41967346 1.4463927 ]\n"]}],"source":["from sklearn.preprocessing import add_dummy_feature\n","X_train_num_hstack1 = add_dummy_feature(X_train_num, 1.0) \n","X_test_num_hstack1 = add_dummy_feature(X_test_num, 1.0)\n","lr = LinearRegression(fit_intercept=False) # fit_intercept=Falseとすることを忘れないように！\n","lr.fit(X_train_num_hstack1, y_train) # 新しく作った行列を使う\n","y_pred_test = lr.predict(X_test_num_hstack1) # 新しく作った行列を使う\n","print(y_pred_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDdwwdK2Zpcx"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["KEcnW_TBZpbr"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}